#Command to run using mahout and hadoop after compiling the mahout source and setting path in bashrc. This uses hadoop implementation of mahout algorithms. These paths given were of hdfs. The files were transfered on hdfs and then ran it. It took 30 minutes to run this program for 1GB of data of ratings and for 10000 users. AWS EC2(m3 large instance) was used to run it.

mahout org.apache.mahout.cf.taste.hadoop.item.RecommenderJob -Dmapred.input.dir=/user/hduser/selectedrating.csv -Dmapred.output.dir=./output200 --usersFile /user/hduser/user.csv --numRecommendations 5  --similarityClassname SIMILARITY_COOCCURRENCE --minPrefsPerUser 1 --maxPrefsPerUser 1000